{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UCIstudentperformance.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4CtV+kg15Cycz56gzKLB6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hellofidan/python/blob/master/UCIstudentperformance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ODK5ILLfTzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOKU6rszfd0s",
        "colab_type": "code",
        "outputId": "dbf67ed7-d00f-431c-c712-e86f98cd9599",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4d584e32-7801-423a-abf3-d9354dd076a5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4d584e32-7801-423a-abf3-d9354dd076a5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving student-mat.csv to student-mat (6).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvfZZeV1iMEw",
        "colab_type": "code",
        "outputId": "7ab63fe4-d865-49f1-8486-87fac176941c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['student-mat.csv']),sep=';')\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>school</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>address</th>\n",
              "      <th>famsize</th>\n",
              "      <th>Pstatus</th>\n",
              "      <th>Medu</th>\n",
              "      <th>Fedu</th>\n",
              "      <th>Mjob</th>\n",
              "      <th>Fjob</th>\n",
              "      <th>reason</th>\n",
              "      <th>guardian</th>\n",
              "      <th>traveltime</th>\n",
              "      <th>studytime</th>\n",
              "      <th>failures</th>\n",
              "      <th>schoolsup</th>\n",
              "      <th>famsup</th>\n",
              "      <th>paid</th>\n",
              "      <th>activities</th>\n",
              "      <th>nursery</th>\n",
              "      <th>higher</th>\n",
              "      <th>internet</th>\n",
              "      <th>romantic</th>\n",
              "      <th>famrel</th>\n",
              "      <th>freetime</th>\n",
              "      <th>goout</th>\n",
              "      <th>Dalc</th>\n",
              "      <th>Walc</th>\n",
              "      <th>health</th>\n",
              "      <th>absences</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>G3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>18</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>A</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>at_home</td>\n",
              "      <td>teacher</td>\n",
              "      <td>course</td>\n",
              "      <td>mother</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>17</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>at_home</td>\n",
              "      <td>other</td>\n",
              "      <td>course</td>\n",
              "      <td>father</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>15</td>\n",
              "      <td>U</td>\n",
              "      <td>LE3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>at_home</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>mother</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>15</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>health</td>\n",
              "      <td>services</td>\n",
              "      <td>home</td>\n",
              "      <td>mother</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>16</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>home</td>\n",
              "      <td>father</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>MS</td>\n",
              "      <td>M</td>\n",
              "      <td>20</td>\n",
              "      <td>U</td>\n",
              "      <td>LE3</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>services</td>\n",
              "      <td>services</td>\n",
              "      <td>course</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>MS</td>\n",
              "      <td>M</td>\n",
              "      <td>17</td>\n",
              "      <td>U</td>\n",
              "      <td>LE3</td>\n",
              "      <td>T</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>services</td>\n",
              "      <td>services</td>\n",
              "      <td>course</td>\n",
              "      <td>mother</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>MS</td>\n",
              "      <td>M</td>\n",
              "      <td>21</td>\n",
              "      <td>R</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>course</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>MS</td>\n",
              "      <td>M</td>\n",
              "      <td>18</td>\n",
              "      <td>R</td>\n",
              "      <td>LE3</td>\n",
              "      <td>T</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>services</td>\n",
              "      <td>other</td>\n",
              "      <td>course</td>\n",
              "      <td>mother</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>MS</td>\n",
              "      <td>M</td>\n",
              "      <td>19</td>\n",
              "      <td>U</td>\n",
              "      <td>LE3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>other</td>\n",
              "      <td>at_home</td>\n",
              "      <td>course</td>\n",
              "      <td>father</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>395 rows Ã— 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    school sex  age address famsize Pstatus  ...  Walc  health absences  G1  G2  G3\n",
              "0       GP   F   18       U     GT3       A  ...     1       3        6   5   6   6\n",
              "1       GP   F   17       U     GT3       T  ...     1       3        4   5   5   6\n",
              "2       GP   F   15       U     LE3       T  ...     3       3       10   7   8  10\n",
              "3       GP   F   15       U     GT3       T  ...     1       5        2  15  14  15\n",
              "4       GP   F   16       U     GT3       T  ...     2       5        4   6  10  10\n",
              "..     ...  ..  ...     ...     ...     ...  ...   ...     ...      ...  ..  ..  ..\n",
              "390     MS   M   20       U     LE3       A  ...     5       4       11   9   9   9\n",
              "391     MS   M   17       U     LE3       T  ...     4       2        3  14  16  16\n",
              "392     MS   M   21       R     GT3       T  ...     3       3        3  10   8   7\n",
              "393     MS   M   18       R     LE3       T  ...     4       5        0  11  12  10\n",
              "394     MS   M   19       U     LE3       T  ...     3       5        5   8   9   9\n",
              "\n",
              "[395 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgZXLG8liXmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3N-0kOpkO_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = list(X.select_dtypes(include=['object']).copy().columns)\n",
        "X= pd.get_dummies(X, columns=columns)\n",
        "y = pd.DataFrame(y)\n",
        "\n",
        "y=y['G3']>10\n",
        "\n",
        "from sklearn.preprocessing import  LabelEncoder\n",
        "labelEncoder_y = LabelEncoder()\n",
        "y=labelEncoder_y.fit_transform(y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee4aTdeVyNdy",
        "colab_type": "code",
        "outputId": "a897b184-9b26-42fd-9069-2ffc41eddc81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = pd.DataFrame(data=y, columns=['G3'])\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sSJ3fPYm1pt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "from keras.regularizers import l2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoljnopG0CvM",
        "colab_type": "code",
        "outputId": "340d32e8-7d45-4d5c-d0e3-4348e1024749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.regularizers import l2\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=58, activation='relu',kernel_regularizer=l2(0.1), bias_regularizer=l2(0.1)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=10, validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 276 samples, validate on 119 samples\n",
            "Epoch 1/150\n",
            "276/276 [==============================] - 0s 695us/step - loss: 7.9990 - accuracy: 0.7826 - val_loss: 5.1111 - val_accuracy: 0.9076\n",
            "Epoch 2/150\n",
            "276/276 [==============================] - 0s 316us/step - loss: 3.7298 - accuracy: 0.8696 - val_loss: 2.3720 - val_accuracy: 0.9244\n",
            "Epoch 3/150\n",
            "276/276 [==============================] - 0s 271us/step - loss: 1.8401 - accuracy: 0.8877 - val_loss: 1.3284 - val_accuracy: 0.8992\n",
            "Epoch 4/150\n",
            "276/276 [==============================] - 0s 273us/step - loss: 1.1695 - accuracy: 0.8442 - val_loss: 0.8889 - val_accuracy: 0.8992\n",
            "Epoch 5/150\n",
            "276/276 [==============================] - 0s 255us/step - loss: 0.7605 - accuracy: 0.8877 - val_loss: 0.6093 - val_accuracy: 0.9328\n",
            "Epoch 6/150\n",
            "276/276 [==============================] - 0s 264us/step - loss: 0.6880 - accuracy: 0.8551 - val_loss: 0.5846 - val_accuracy: 0.8992\n",
            "Epoch 7/150\n",
            "276/276 [==============================] - 0s 263us/step - loss: 0.5328 - accuracy: 0.8841 - val_loss: 0.7137 - val_accuracy: 0.7983\n",
            "Epoch 8/150\n",
            "276/276 [==============================] - 0s 286us/step - loss: 0.5808 - accuracy: 0.8659 - val_loss: 0.4245 - val_accuracy: 0.9244\n",
            "Epoch 9/150\n",
            "276/276 [==============================] - 0s 273us/step - loss: 0.4247 - accuracy: 0.9203 - val_loss: 0.3650 - val_accuracy: 0.9412\n",
            "Epoch 10/150\n",
            "276/276 [==============================] - 0s 266us/step - loss: 0.3855 - accuracy: 0.9094 - val_loss: 0.3696 - val_accuracy: 0.9244\n",
            "Epoch 11/150\n",
            "276/276 [==============================] - 0s 264us/step - loss: 0.4078 - accuracy: 0.8986 - val_loss: 0.3077 - val_accuracy: 0.9496\n",
            "Epoch 12/150\n",
            "276/276 [==============================] - 0s 258us/step - loss: 0.3621 - accuracy: 0.9094 - val_loss: 0.3891 - val_accuracy: 0.9076\n",
            "Epoch 13/150\n",
            "276/276 [==============================] - 0s 265us/step - loss: 0.3339 - accuracy: 0.9130 - val_loss: 0.2934 - val_accuracy: 0.9412\n",
            "Epoch 14/150\n",
            "276/276 [==============================] - 0s 262us/step - loss: 0.3443 - accuracy: 0.9058 - val_loss: 0.2925 - val_accuracy: 0.9244\n",
            "Epoch 15/150\n",
            "276/276 [==============================] - 0s 291us/step - loss: 0.3698 - accuracy: 0.8877 - val_loss: 0.2704 - val_accuracy: 0.9328\n",
            "Epoch 16/150\n",
            "276/276 [==============================] - 0s 275us/step - loss: 0.2967 - accuracy: 0.9239 - val_loss: 0.2720 - val_accuracy: 0.9496\n",
            "Epoch 17/150\n",
            "276/276 [==============================] - 0s 250us/step - loss: 0.2890 - accuracy: 0.9167 - val_loss: 0.2791 - val_accuracy: 0.9412\n",
            "Epoch 18/150\n",
            "276/276 [==============================] - 0s 278us/step - loss: 0.3079 - accuracy: 0.9058 - val_loss: 0.3113 - val_accuracy: 0.9160\n",
            "Epoch 19/150\n",
            "276/276 [==============================] - 0s 255us/step - loss: 0.3125 - accuracy: 0.9094 - val_loss: 0.2320 - val_accuracy: 0.9412\n",
            "Epoch 20/150\n",
            "276/276 [==============================] - 0s 259us/step - loss: 0.3155 - accuracy: 0.9094 - val_loss: 0.4529 - val_accuracy: 0.8319\n",
            "Epoch 21/150\n",
            "276/276 [==============================] - 0s 266us/step - loss: 0.3118 - accuracy: 0.9167 - val_loss: 0.2402 - val_accuracy: 0.9160\n",
            "Epoch 22/150\n",
            "276/276 [==============================] - 0s 258us/step - loss: 0.2610 - accuracy: 0.9312 - val_loss: 0.2273 - val_accuracy: 0.9412\n",
            "Epoch 23/150\n",
            "276/276 [==============================] - 0s 254us/step - loss: 0.2909 - accuracy: 0.9167 - val_loss: 0.3363 - val_accuracy: 0.8992\n",
            "Epoch 24/150\n",
            "276/276 [==============================] - 0s 271us/step - loss: 0.2523 - accuracy: 0.9312 - val_loss: 0.2350 - val_accuracy: 0.9496\n",
            "Epoch 25/150\n",
            "276/276 [==============================] - 0s 260us/step - loss: 0.2567 - accuracy: 0.9239 - val_loss: 0.2694 - val_accuracy: 0.9412\n",
            "Epoch 26/150\n",
            "276/276 [==============================] - 0s 262us/step - loss: 0.2754 - accuracy: 0.9058 - val_loss: 0.2284 - val_accuracy: 0.9496\n",
            "Epoch 27/150\n",
            "276/276 [==============================] - 0s 294us/step - loss: 0.2554 - accuracy: 0.8986 - val_loss: 0.4215 - val_accuracy: 0.8655\n",
            "Epoch 28/150\n",
            "276/276 [==============================] - 0s 289us/step - loss: 0.3071 - accuracy: 0.8986 - val_loss: 0.2247 - val_accuracy: 0.9328\n",
            "Epoch 29/150\n",
            "276/276 [==============================] - 0s 295us/step - loss: 0.2323 - accuracy: 0.9275 - val_loss: 0.2163 - val_accuracy: 0.9496\n",
            "Epoch 30/150\n",
            "276/276 [==============================] - 0s 278us/step - loss: 0.2402 - accuracy: 0.9167 - val_loss: 0.2148 - val_accuracy: 0.9496\n",
            "Epoch 31/150\n",
            "276/276 [==============================] - 0s 265us/step - loss: 0.2584 - accuracy: 0.9022 - val_loss: 0.2924 - val_accuracy: 0.9076\n",
            "Epoch 32/150\n",
            "276/276 [==============================] - 0s 259us/step - loss: 0.2703 - accuracy: 0.9022 - val_loss: 0.2295 - val_accuracy: 0.9496\n",
            "Epoch 33/150\n",
            "276/276 [==============================] - 0s 279us/step - loss: 0.3226 - accuracy: 0.8768 - val_loss: 0.2819 - val_accuracy: 0.9160\n",
            "Epoch 34/150\n",
            "276/276 [==============================] - 0s 269us/step - loss: 0.2468 - accuracy: 0.9203 - val_loss: 0.2086 - val_accuracy: 0.9412\n",
            "Epoch 35/150\n",
            "276/276 [==============================] - 0s 256us/step - loss: 0.2671 - accuracy: 0.9130 - val_loss: 0.2146 - val_accuracy: 0.9160\n",
            "Epoch 36/150\n",
            "276/276 [==============================] - 0s 266us/step - loss: 0.2205 - accuracy: 0.9420 - val_loss: 0.2338 - val_accuracy: 0.9328\n",
            "Epoch 37/150\n",
            "276/276 [==============================] - 0s 266us/step - loss: 0.3182 - accuracy: 0.8949 - val_loss: 0.2069 - val_accuracy: 0.9580\n",
            "Epoch 38/150\n",
            "276/276 [==============================] - 0s 266us/step - loss: 0.2666 - accuracy: 0.9058 - val_loss: 0.2168 - val_accuracy: 0.9412\n",
            "Epoch 39/150\n",
            "276/276 [==============================] - 0s 265us/step - loss: 0.2313 - accuracy: 0.9167 - val_loss: 0.2057 - val_accuracy: 0.9412\n",
            "Epoch 40/150\n",
            "276/276 [==============================] - 0s 258us/step - loss: 0.2165 - accuracy: 0.9420 - val_loss: 0.2577 - val_accuracy: 0.9328\n",
            "Epoch 41/150\n",
            "276/276 [==============================] - 0s 284us/step - loss: 0.2119 - accuracy: 0.9275 - val_loss: 0.2242 - val_accuracy: 0.9412\n",
            "Epoch 42/150\n",
            "276/276 [==============================] - 0s 281us/step - loss: 0.2135 - accuracy: 0.9239 - val_loss: 0.1866 - val_accuracy: 0.9496\n",
            "Epoch 43/150\n",
            "276/276 [==============================] - 0s 263us/step - loss: 0.2258 - accuracy: 0.9203 - val_loss: 0.2026 - val_accuracy: 0.9412\n",
            "Epoch 44/150\n",
            "276/276 [==============================] - 0s 264us/step - loss: 0.2269 - accuracy: 0.9420 - val_loss: 0.3232 - val_accuracy: 0.8908\n",
            "Epoch 45/150\n",
            "276/276 [==============================] - 0s 264us/step - loss: 0.2117 - accuracy: 0.9348 - val_loss: 0.2181 - val_accuracy: 0.9412\n",
            "Epoch 46/150\n",
            "276/276 [==============================] - 0s 270us/step - loss: 0.2073 - accuracy: 0.9420 - val_loss: 0.2393 - val_accuracy: 0.9412\n",
            "Epoch 47/150\n",
            "276/276 [==============================] - 0s 256us/step - loss: 0.2060 - accuracy: 0.9275 - val_loss: 0.2048 - val_accuracy: 0.9496\n",
            "Epoch 48/150\n",
            "276/276 [==============================] - 0s 261us/step - loss: 0.1987 - accuracy: 0.9275 - val_loss: 0.1961 - val_accuracy: 0.9496\n",
            "Epoch 49/150\n",
            "276/276 [==============================] - 0s 280us/step - loss: 0.2368 - accuracy: 0.9203 - val_loss: 0.2085 - val_accuracy: 0.9076\n",
            "Epoch 50/150\n",
            "276/276 [==============================] - 0s 286us/step - loss: 0.2483 - accuracy: 0.9130 - val_loss: 0.1870 - val_accuracy: 0.9496\n",
            "Epoch 51/150\n",
            "276/276 [==============================] - 0s 254us/step - loss: 0.2260 - accuracy: 0.9094 - val_loss: 0.2579 - val_accuracy: 0.9244\n",
            "Epoch 52/150\n",
            "276/276 [==============================] - 0s 262us/step - loss: 0.2088 - accuracy: 0.9275 - val_loss: 0.1956 - val_accuracy: 0.9160\n",
            "Epoch 53/150\n",
            "276/276 [==============================] - 0s 280us/step - loss: 0.2011 - accuracy: 0.9348 - val_loss: 0.2250 - val_accuracy: 0.9412\n",
            "Epoch 54/150\n",
            "276/276 [==============================] - 0s 260us/step - loss: 0.2083 - accuracy: 0.9384 - val_loss: 0.2055 - val_accuracy: 0.9412\n",
            "Epoch 55/150\n",
            "276/276 [==============================] - 0s 282us/step - loss: 0.1942 - accuracy: 0.9420 - val_loss: 0.1933 - val_accuracy: 0.9412\n",
            "Epoch 56/150\n",
            "276/276 [==============================] - 0s 289us/step - loss: 0.1843 - accuracy: 0.9384 - val_loss: 0.2046 - val_accuracy: 0.9328\n",
            "Epoch 57/150\n",
            "276/276 [==============================] - 0s 267us/step - loss: 0.1881 - accuracy: 0.9384 - val_loss: 0.2306 - val_accuracy: 0.9412\n",
            "Epoch 58/150\n",
            "276/276 [==============================] - 0s 271us/step - loss: 0.2156 - accuracy: 0.9348 - val_loss: 0.3784 - val_accuracy: 0.8908\n",
            "Epoch 59/150\n",
            "276/276 [==============================] - 0s 275us/step - loss: 0.2808 - accuracy: 0.9094 - val_loss: 0.3697 - val_accuracy: 0.8655\n",
            "Epoch 60/150\n",
            "276/276 [==============================] - 0s 322us/step - loss: 0.2170 - accuracy: 0.9312 - val_loss: 0.2177 - val_accuracy: 0.9412\n",
            "Epoch 61/150\n",
            "276/276 [==============================] - 0s 267us/step - loss: 0.2207 - accuracy: 0.9130 - val_loss: 0.2982 - val_accuracy: 0.8992\n",
            "Epoch 62/150\n",
            "276/276 [==============================] - 0s 269us/step - loss: 0.2017 - accuracy: 0.9130 - val_loss: 0.2013 - val_accuracy: 0.9412\n",
            "Epoch 63/150\n",
            "276/276 [==============================] - 0s 269us/step - loss: 0.1750 - accuracy: 0.9601 - val_loss: 0.2096 - val_accuracy: 0.8992\n",
            "Epoch 64/150\n",
            "276/276 [==============================] - 0s 264us/step - loss: 0.1920 - accuracy: 0.9312 - val_loss: 0.1903 - val_accuracy: 0.9496\n",
            "Epoch 65/150\n",
            "276/276 [==============================] - 0s 276us/step - loss: 0.1930 - accuracy: 0.9167 - val_loss: 0.1928 - val_accuracy: 0.9244\n",
            "Epoch 66/150\n",
            "276/276 [==============================] - 0s 278us/step - loss: 0.1824 - accuracy: 0.9420 - val_loss: 0.2127 - val_accuracy: 0.9412\n",
            "Epoch 67/150\n",
            "276/276 [==============================] - 0s 257us/step - loss: 0.1860 - accuracy: 0.9384 - val_loss: 0.1832 - val_accuracy: 0.9244\n",
            "Epoch 68/150\n",
            "276/276 [==============================] - 0s 270us/step - loss: 0.1773 - accuracy: 0.9529 - val_loss: 0.1926 - val_accuracy: 0.8992\n",
            "Epoch 69/150\n",
            "276/276 [==============================] - 0s 281us/step - loss: 0.1750 - accuracy: 0.9420 - val_loss: 0.2673 - val_accuracy: 0.9160\n",
            "Epoch 70/150\n",
            "276/276 [==============================] - 0s 263us/step - loss: 0.3194 - accuracy: 0.8768 - val_loss: 0.3463 - val_accuracy: 0.8739\n",
            "Epoch 71/150\n",
            "276/276 [==============================] - 0s 276us/step - loss: 0.2461 - accuracy: 0.9239 - val_loss: 0.2284 - val_accuracy: 0.9244\n",
            "Epoch 72/150\n",
            "276/276 [==============================] - 0s 254us/step - loss: 0.1919 - accuracy: 0.9239 - val_loss: 0.1879 - val_accuracy: 0.9496\n",
            "Epoch 73/150\n",
            "276/276 [==============================] - 0s 271us/step - loss: 0.1890 - accuracy: 0.9275 - val_loss: 0.1989 - val_accuracy: 0.9328\n",
            "Epoch 74/150\n",
            "276/276 [==============================] - 0s 259us/step - loss: 0.1965 - accuracy: 0.9312 - val_loss: 0.2616 - val_accuracy: 0.9244\n",
            "Epoch 75/150\n",
            "276/276 [==============================] - 0s 267us/step - loss: 0.1906 - accuracy: 0.9384 - val_loss: 0.1905 - val_accuracy: 0.9496\n",
            "Epoch 76/150\n",
            "276/276 [==============================] - 0s 279us/step - loss: 0.1890 - accuracy: 0.9457 - val_loss: 0.2514 - val_accuracy: 0.8908\n",
            "Epoch 77/150\n",
            "276/276 [==============================] - 0s 266us/step - loss: 0.1860 - accuracy: 0.9457 - val_loss: 0.2469 - val_accuracy: 0.9328\n",
            "Epoch 78/150\n",
            "276/276 [==============================] - 0s 262us/step - loss: 0.1975 - accuracy: 0.9275 - val_loss: 0.2225 - val_accuracy: 0.9412\n",
            "Epoch 79/150\n",
            "276/276 [==============================] - 0s 271us/step - loss: 0.2004 - accuracy: 0.9203 - val_loss: 0.2277 - val_accuracy: 0.9412\n",
            "Epoch 80/150\n",
            "276/276 [==============================] - 0s 277us/step - loss: 0.1914 - accuracy: 0.9312 - val_loss: 0.1932 - val_accuracy: 0.9244\n",
            "Epoch 81/150\n",
            "276/276 [==============================] - 0s 269us/step - loss: 0.2531 - accuracy: 0.9022 - val_loss: 0.2016 - val_accuracy: 0.9244\n",
            "Epoch 82/150\n",
            "276/276 [==============================] - 0s 291us/step - loss: 0.1720 - accuracy: 0.9493 - val_loss: 0.2693 - val_accuracy: 0.8992\n",
            "Epoch 83/150\n",
            "276/276 [==============================] - 0s 271us/step - loss: 0.1708 - accuracy: 0.9457 - val_loss: 0.2312 - val_accuracy: 0.9244\n",
            "Epoch 84/150\n",
            "276/276 [==============================] - 0s 252us/step - loss: 0.1699 - accuracy: 0.9420 - val_loss: 0.1915 - val_accuracy: 0.9328\n",
            "Epoch 85/150\n",
            "276/276 [==============================] - 0s 296us/step - loss: 0.2420 - accuracy: 0.9130 - val_loss: 0.3791 - val_accuracy: 0.8655\n",
            "Epoch 86/150\n",
            "276/276 [==============================] - 0s 266us/step - loss: 0.2221 - accuracy: 0.9239 - val_loss: 0.2050 - val_accuracy: 0.9328\n",
            "Epoch 87/150\n",
            "276/276 [==============================] - 0s 266us/step - loss: 0.2551 - accuracy: 0.8949 - val_loss: 0.2047 - val_accuracy: 0.9076\n",
            "Epoch 88/150\n",
            "276/276 [==============================] - 0s 282us/step - loss: 0.1875 - accuracy: 0.9457 - val_loss: 0.2071 - val_accuracy: 0.9412\n",
            "Epoch 89/150\n",
            "276/276 [==============================] - 0s 259us/step - loss: 0.1980 - accuracy: 0.9348 - val_loss: 0.2326 - val_accuracy: 0.9244\n",
            "Epoch 90/150\n",
            "276/276 [==============================] - 0s 259us/step - loss: 0.1590 - accuracy: 0.9565 - val_loss: 0.1911 - val_accuracy: 0.9496\n",
            "Epoch 91/150\n",
            "276/276 [==============================] - 0s 266us/step - loss: 0.1839 - accuracy: 0.9384 - val_loss: 0.2858 - val_accuracy: 0.9076\n",
            "Epoch 92/150\n",
            "276/276 [==============================] - 0s 271us/step - loss: 0.1802 - accuracy: 0.9384 - val_loss: 0.2245 - val_accuracy: 0.9328\n",
            "Epoch 93/150\n",
            "276/276 [==============================] - 0s 273us/step - loss: 0.1798 - accuracy: 0.9348 - val_loss: 0.2293 - val_accuracy: 0.9244\n",
            "Epoch 94/150\n",
            "276/276 [==============================] - 0s 258us/step - loss: 0.1703 - accuracy: 0.9457 - val_loss: 0.2942 - val_accuracy: 0.9076\n",
            "Epoch 95/150\n",
            "276/276 [==============================] - 0s 262us/step - loss: 0.2261 - accuracy: 0.8986 - val_loss: 0.2228 - val_accuracy: 0.8992\n",
            "Epoch 96/150\n",
            "276/276 [==============================] - 0s 280us/step - loss: 0.3018 - accuracy: 0.8949 - val_loss: 0.3441 - val_accuracy: 0.8739\n",
            "Epoch 97/150\n",
            "276/276 [==============================] - 0s 271us/step - loss: 0.2020 - accuracy: 0.9275 - val_loss: 0.2231 - val_accuracy: 0.9328\n",
            "Epoch 98/150\n",
            "276/276 [==============================] - 0s 276us/step - loss: 0.2137 - accuracy: 0.9348 - val_loss: 0.3844 - val_accuracy: 0.8655\n",
            "Epoch 99/150\n",
            "276/276 [==============================] - 0s 272us/step - loss: 0.2345 - accuracy: 0.9203 - val_loss: 0.2017 - val_accuracy: 0.9412\n",
            "Epoch 100/150\n",
            "276/276 [==============================] - 0s 278us/step - loss: 0.1746 - accuracy: 0.9384 - val_loss: 0.2052 - val_accuracy: 0.9328\n",
            "Epoch 101/150\n",
            "276/276 [==============================] - 0s 272us/step - loss: 0.1635 - accuracy: 0.9565 - val_loss: 0.2068 - val_accuracy: 0.9412\n",
            "Epoch 102/150\n",
            "276/276 [==============================] - 0s 282us/step - loss: 0.1597 - accuracy: 0.9529 - val_loss: 0.1920 - val_accuracy: 0.9412\n",
            "Epoch 103/150\n",
            "276/276 [==============================] - 0s 264us/step - loss: 0.1543 - accuracy: 0.9529 - val_loss: 0.2025 - val_accuracy: 0.9412\n",
            "Epoch 104/150\n",
            "276/276 [==============================] - 0s 269us/step - loss: 0.1484 - accuracy: 0.9457 - val_loss: 0.2474 - val_accuracy: 0.9244\n",
            "Epoch 105/150\n",
            "276/276 [==============================] - 0s 299us/step - loss: 0.1752 - accuracy: 0.9420 - val_loss: 0.4151 - val_accuracy: 0.8655\n",
            "Epoch 106/150\n",
            "276/276 [==============================] - 0s 283us/step - loss: 0.1911 - accuracy: 0.9348 - val_loss: 0.1956 - val_accuracy: 0.9328\n",
            "Epoch 107/150\n",
            "276/276 [==============================] - 0s 261us/step - loss: 0.1768 - accuracy: 0.9420 - val_loss: 0.2424 - val_accuracy: 0.9328\n",
            "Epoch 108/150\n",
            "276/276 [==============================] - 0s 283us/step - loss: 0.1508 - accuracy: 0.9565 - val_loss: 0.1874 - val_accuracy: 0.9328\n",
            "Epoch 109/150\n",
            "276/276 [==============================] - 0s 288us/step - loss: 0.1515 - accuracy: 0.9493 - val_loss: 0.1949 - val_accuracy: 0.9160\n",
            "Epoch 110/150\n",
            "276/276 [==============================] - 0s 264us/step - loss: 0.1510 - accuracy: 0.9493 - val_loss: 0.1920 - val_accuracy: 0.9244\n",
            "Epoch 111/150\n",
            "276/276 [==============================] - 0s 275us/step - loss: 0.1437 - accuracy: 0.9674 - val_loss: 0.2008 - val_accuracy: 0.9412\n",
            "Epoch 112/150\n",
            "276/276 [==============================] - 0s 270us/step - loss: 0.1517 - accuracy: 0.9529 - val_loss: 0.2168 - val_accuracy: 0.9328\n",
            "Epoch 113/150\n",
            "276/276 [==============================] - 0s 265us/step - loss: 0.1791 - accuracy: 0.9384 - val_loss: 0.2178 - val_accuracy: 0.9412\n",
            "Epoch 114/150\n",
            "276/276 [==============================] - 0s 275us/step - loss: 0.1844 - accuracy: 0.9312 - val_loss: 0.2128 - val_accuracy: 0.9076\n",
            "Epoch 115/150\n",
            "276/276 [==============================] - 0s 257us/step - loss: 0.1763 - accuracy: 0.9384 - val_loss: 0.2300 - val_accuracy: 0.9412\n",
            "Epoch 116/150\n",
            "276/276 [==============================] - 0s 269us/step - loss: 0.1767 - accuracy: 0.9420 - val_loss: 0.2173 - val_accuracy: 0.9076\n",
            "Epoch 117/150\n",
            "276/276 [==============================] - 0s 267us/step - loss: 0.2345 - accuracy: 0.9130 - val_loss: 0.2265 - val_accuracy: 0.9412\n",
            "Epoch 118/150\n",
            "276/276 [==============================] - 0s 267us/step - loss: 0.1491 - accuracy: 0.9601 - val_loss: 0.2911 - val_accuracy: 0.8992\n",
            "Epoch 119/150\n",
            "276/276 [==============================] - 0s 280us/step - loss: 0.1440 - accuracy: 0.9565 - val_loss: 0.2200 - val_accuracy: 0.9496\n",
            "Epoch 120/150\n",
            "276/276 [==============================] - 0s 263us/step - loss: 0.2526 - accuracy: 0.9167 - val_loss: 0.3075 - val_accuracy: 0.8992\n",
            "Epoch 121/150\n",
            "276/276 [==============================] - 0s 278us/step - loss: 0.1725 - accuracy: 0.9457 - val_loss: 0.2206 - val_accuracy: 0.9328\n",
            "Epoch 122/150\n",
            "276/276 [==============================] - 0s 298us/step - loss: 0.1499 - accuracy: 0.9457 - val_loss: 0.3016 - val_accuracy: 0.8992\n",
            "Epoch 123/150\n",
            "276/276 [==============================] - 0s 267us/step - loss: 0.1493 - accuracy: 0.9493 - val_loss: 0.2016 - val_accuracy: 0.9160\n",
            "Epoch 124/150\n",
            "276/276 [==============================] - 0s 260us/step - loss: 0.1595 - accuracy: 0.9457 - val_loss: 0.2499 - val_accuracy: 0.9244\n",
            "Epoch 125/150\n",
            "276/276 [==============================] - 0s 305us/step - loss: 0.1410 - accuracy: 0.9529 - val_loss: 0.2108 - val_accuracy: 0.9328\n",
            "Epoch 126/150\n",
            "276/276 [==============================] - 0s 259us/step - loss: 0.1434 - accuracy: 0.9601 - val_loss: 0.2839 - val_accuracy: 0.9076\n",
            "Epoch 127/150\n",
            "276/276 [==============================] - 0s 258us/step - loss: 0.1536 - accuracy: 0.9529 - val_loss: 0.2082 - val_accuracy: 0.9076\n",
            "Epoch 128/150\n",
            "276/276 [==============================] - 0s 292us/step - loss: 0.1502 - accuracy: 0.9638 - val_loss: 0.2095 - val_accuracy: 0.9160\n",
            "Epoch 129/150\n",
            "276/276 [==============================] - 0s 261us/step - loss: 0.1579 - accuracy: 0.9420 - val_loss: 0.2289 - val_accuracy: 0.9412\n",
            "Epoch 130/150\n",
            "276/276 [==============================] - 0s 257us/step - loss: 0.1400 - accuracy: 0.9493 - val_loss: 0.1946 - val_accuracy: 0.9244\n",
            "Epoch 131/150\n",
            "276/276 [==============================] - 0s 269us/step - loss: 0.1469 - accuracy: 0.9529 - val_loss: 0.2929 - val_accuracy: 0.9160\n",
            "Epoch 132/150\n",
            "276/276 [==============================] - 0s 269us/step - loss: 0.1268 - accuracy: 0.9746 - val_loss: 0.2067 - val_accuracy: 0.9160\n",
            "Epoch 133/150\n",
            "276/276 [==============================] - 0s 270us/step - loss: 0.1827 - accuracy: 0.9384 - val_loss: 0.2209 - val_accuracy: 0.9496\n",
            "Epoch 134/150\n",
            "276/276 [==============================] - 0s 259us/step - loss: 0.1614 - accuracy: 0.9493 - val_loss: 0.2177 - val_accuracy: 0.9328\n",
            "Epoch 135/150\n",
            "276/276 [==============================] - 0s 288us/step - loss: 0.1374 - accuracy: 0.9601 - val_loss: 0.2749 - val_accuracy: 0.8908\n",
            "Epoch 136/150\n",
            "276/276 [==============================] - 0s 314us/step - loss: 0.1654 - accuracy: 0.9493 - val_loss: 0.2342 - val_accuracy: 0.9496\n",
            "Epoch 137/150\n",
            "276/276 [==============================] - 0s 270us/step - loss: 0.1760 - accuracy: 0.9384 - val_loss: 0.1989 - val_accuracy: 0.9160\n",
            "Epoch 138/150\n",
            "276/276 [==============================] - 0s 268us/step - loss: 0.1459 - accuracy: 0.9420 - val_loss: 0.2123 - val_accuracy: 0.9412\n",
            "Epoch 139/150\n",
            "276/276 [==============================] - 0s 279us/step - loss: 0.1669 - accuracy: 0.9420 - val_loss: 0.3083 - val_accuracy: 0.8992\n",
            "Epoch 140/150\n",
            "276/276 [==============================] - 0s 259us/step - loss: 0.1613 - accuracy: 0.9493 - val_loss: 0.1990 - val_accuracy: 0.9412\n",
            "Epoch 141/150\n",
            "276/276 [==============================] - 0s 282us/step - loss: 0.1405 - accuracy: 0.9565 - val_loss: 0.2195 - val_accuracy: 0.9328\n",
            "Epoch 142/150\n",
            "276/276 [==============================] - 0s 259us/step - loss: 0.1285 - accuracy: 0.9601 - val_loss: 0.2155 - val_accuracy: 0.9496\n",
            "Epoch 143/150\n",
            "276/276 [==============================] - 0s 267us/step - loss: 0.1469 - accuracy: 0.9529 - val_loss: 0.2111 - val_accuracy: 0.9328\n",
            "Epoch 144/150\n",
            "276/276 [==============================] - 0s 301us/step - loss: 0.1513 - accuracy: 0.9529 - val_loss: 0.2143 - val_accuracy: 0.9244\n",
            "Epoch 145/150\n",
            "276/276 [==============================] - 0s 271us/step - loss: 0.1773 - accuracy: 0.9529 - val_loss: 0.2235 - val_accuracy: 0.9328\n",
            "Epoch 146/150\n",
            "276/276 [==============================] - 0s 254us/step - loss: 0.1378 - accuracy: 0.9529 - val_loss: 0.2095 - val_accuracy: 0.9244\n",
            "Epoch 147/150\n",
            "276/276 [==============================] - 0s 286us/step - loss: 0.1190 - accuracy: 0.9638 - val_loss: 0.2852 - val_accuracy: 0.9244\n",
            "Epoch 148/150\n",
            "276/276 [==============================] - 0s 290us/step - loss: 0.1580 - accuracy: 0.9348 - val_loss: 0.2931 - val_accuracy: 0.8824\n",
            "Epoch 149/150\n",
            "276/276 [==============================] - 0s 259us/step - loss: 0.1611 - accuracy: 0.9312 - val_loss: 0.2297 - val_accuracy: 0.9244\n",
            "Epoch 150/150\n",
            "276/276 [==============================] - 0s 316us/step - loss: 0.1401 - accuracy: 0.9638 - val_loss: 0.2307 - val_accuracy: 0.9328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f3f76aeaa20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fkQ5-_S0_B6",
        "colab_type": "code",
        "outputId": "cf352b81-b77c-44fb-8ee5-e3508b8cbc38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "result_train = model.evaluate(X_train, y_train, batch_size=128)\n",
        "result_test = model.evaluate(X_test, y_test, batch_size=128)\n",
        "\n",
        "print('test acc:', result_test[1])\n",
        "print('train acc:', result_train[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "276/276 [==============================] - 0s 24us/step\n",
            "119/119 [==============================] - 0s 16us/step\n",
            "test acc: 0.9327731132507324\n",
            "train acc: 0.9746376872062683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3bhcMqW66To",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}